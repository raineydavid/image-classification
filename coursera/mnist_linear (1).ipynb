{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow\n",
    "\n",
    "This notebook demonstrates how to implement a simple linear image models on MNIST using Estimator.\n",
    "<hr/>\n",
    "This <a href=\"mnist_models.ipynb\">companion notebook</a> extends the basic harness of this notebook to a variety of models including DNN, CNN, dropout, pooling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a5eb312004ba>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 28, 28, 1)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0c840a4da0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c845185c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO=12\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO=12\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using low-level tensorflow\n",
    "def linear_model(img):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  W = tf.get_variable(\"W\", [HEIGHT* WIDTH, NCLASSES],\n",
    "                      initializer = tf.truncated_normal_initializer(stddev=0.1, seed=1)\n",
    "                     )   \n",
    "  b = tf.get_variable(\"b\", NCLASSES, initializer=tf.zeros_initializer)\n",
    "  ylogits=tf.malmul(X,W)+b\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using low-level tensorflow\n",
    "def linear_model(img):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  W = tf.get_variable(\"W\", [HEIGHT*WIDTH,NCLASSES], \n",
    "                      initializer = tf.truncated_normal_initializer(stddev=0.1,seed = 1))\n",
    "  b = tf.get_variable(\"b\",NCLASSES, initializer = tf.zeros_initializer)\n",
    "  ylogits = tf.matmul(X,W)+b\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we can also build our linear classifer using the tf.layers API. Notice when using tf.layers we don't have to define or initialize our weights and biases. This happens automatically for us in the background.\n",
    "\n",
    "When building more complex models such as DNNs and CNNs our code will be much more readable by using the tf.layers API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using tf.layers API\n",
    "def linear_model(img):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  ylogits = tf.layers.dense(X,NCLASSES,activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using tf.layers API\n",
    "def linear_model(img):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  ylogits = tf.layers.dense(X,NCLASSES,activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Input Functions\n",
    "\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={'image':mnist.train.images},\n",
    "  y=mnist.train.labels,\n",
    "  batch_size=100,\n",
    "  num_epochs=None,\n",
    "  shuffle=True,\n",
    "  queue_capacity=5000\n",
    ")\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={'image':mnist.test.images},\n",
    "  y=mnist.test.labels,\n",
    "  batch_size=100,\n",
    "  num_epochs=1,\n",
    "  shuffle=True,\n",
    "  queue_capacity=5000\n",
    ")\n",
    "\n",
    "def serving_input_fn():\n",
    "  inputs = {'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
    "  features = inputs # as-is\n",
    "  return tf.estimator.export.ServingInputReceiver(features,inputs)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.train.images},\n",
    "    y=mnist.train.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.test.images},\n",
    "    y=mnist.test.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "def serving_input_fn():\n",
    "    inputs = {'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
    "    features = inputs # as-is\n",
    "    return tf.estimator.export.ServingInputReceiver(features, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Custom Estimator\n",
    "I could have simply used a canned LinearClassifier, but later on, I will want to use different models, and so let's write a custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "  ylogits, nclasses = linear_model(features['image'])\n",
    "  probabilities = tf.nn.softmax(ylogits)\n",
    "  classes = tf.cast(tf.argmax(probabilities,1), tf.uint8)\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode ==  tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ylogits, labels=labels))\n",
    "    evalmetrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels,1))}\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
    "                                                learning_rate=params['learning_rate'], optimizer='Adam')\n",
    "    else:\n",
    "      train_op = None\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    evalmetrics = None\n",
    "  \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "          mode=mode,\n",
    "          predictions={'probabilities': probabilities, 'classes': classes},\n",
    "          loss=loss,\n",
    "          train_op=train_op,\n",
    "          eval_metric_ops=evalmetrics,\n",
    "          export_outputs={'classes':tf.estimator.export.PredictOutput({'probabilities': probabilities, 'classes': classes})}\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "  ylogits, nclasses = linear_model(features['image'])\n",
    "  probabilities = tf.nn.softmax(ylogits)\n",
    "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ylogits, labels=labels))\n",
    "    evalmetrics =  {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
    "                                                 learning_rate=params['learning_rate'], optimizer=\"Adam\")\n",
    "    else:\n",
    "      train_op = None\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    evalmetrics = None\n",
    " \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=evalmetrics,\n",
    "        export_outputs={'classes': tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"classes\": classes})}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " tf.estimator.train_and_evaluate does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                    params = hparams,\n",
    "                                    model_dir = output_dir)\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                     max_steps = hparams['train_steps'])\n",
    "  exporter = tf.estimator.LatestExporter('Servo', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn, \n",
    "                                    steps = None,\n",
    "                                    exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                     params = hparams,\n",
    "                                     model_dir = output_dir)\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                    max_steps = hparams['train_steps'])\n",
    "  exporter = tf.estimator.LatestExporter('Servo', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
    "                                  steps = None,\n",
    "                                  exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_master': '', '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_service': None, '_evaluation_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_model_dir': 'mnist/learned', '_log_step_count_steps': 100, '_session_config': None, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0c8184f2b0>}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.449485\n",
      "INFO:tensorflow:global_step/sec: 242.86\n",
      "INFO:tensorflow:step = 101, loss = 0.61481184 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.969\n",
      "INFO:tensorflow:step = 201, loss = 0.56656057 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.212\n",
      "INFO:tensorflow:step = 301, loss = 0.24556768 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.454\n",
      "INFO:tensorflow:step = 401, loss = 0.12517723 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.732\n",
      "INFO:tensorflow:step = 501, loss = 0.47794098 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.529\n",
      "INFO:tensorflow:step = 601, loss = 0.2236973 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.122\n",
      "INFO:tensorflow:step = 701, loss = 0.15731807 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.211\n",
      "INFO:tensorflow:step = 801, loss = 0.09527069 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.403\n",
      "INFO:tensorflow:step = 901, loss = 0.49465293 (0.324 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3939979.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-08-15:05:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-08-15:05:07\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9208, global_step = 1000, loss = 0.2894591\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'classes']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"mnist/learned/export/Servo/temp-b'1554735907'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "OUTDIR='mnist/learned'\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True) # start fresh each time\n",
    "\n",
    "hparams ={'train_steps': 1000, 'learning_rate': 0.01}\n",
    "\n",
    "train_and_evaluate(OUTDIR, hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR='mnist/learned'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {'train_steps': 1000, 'learning_rate': 0.01}\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got:\n",
    "\n",
    "`Saving dict for global step 1000: accuracy = 0.9158, global_step = 1000, loss = 0.29720208`\n",
    "\n",
    "In other words, we achieved 91.6% accuracy with the simple linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
